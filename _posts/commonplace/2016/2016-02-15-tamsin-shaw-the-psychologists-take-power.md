---
layout: entry
category: commonplace
author: Tamsin Shaw
title: The Psychologists Take Power
publication: New York Review of Books
link: http://www.nybooks.com/articles/2016/02/25/the-psychologists-take-power/
date: 2016-02-15
---

“The psychological school of behaviorism sought to replace the idea of human beings as autonomous agents with the “scientific” view of them as biological organisms, responding to external stimuli, whose behavior could be modified by altering their environment.”

“Neuroscience, it is claimed, has revealed that our brains operate with a dual system for moral decision-making. In 2001, Joshua Greene, a philosophy graduate student, teamed up with the neuroscientist Jonathan Cohen to analyze fMRIs of people’s brains as they responded to hypothetical moral dilemmas. They inferred from looking at neural activity in different regions that moral judgment involved two distinct psychological processes. One of the processes, a fast and intuitive one, took place by and large in areas of the brain associated with emotional processing, such as the medial prefrontal cortex and the amygdala. The other process, which was slow and rational, took place by and large in regions associated with cognitive processing, such as the dorsolateral prefrontal cortex and the parietal lobe.”

“But as the philosopher Selim Berker has pointed out in his important paper “The Normative Insignificance of Neuroscience,” the claim here is that personal factors are morally irrelevant, so the neural and psychological processes that track such factors in each person cannot be relied on to support moral propositions or guide moral decisions.”

“Greene’s controversial philosophical claim is simply presupposed; it is in no way motivated by the findings of science. An understanding of the neural correlates of reasoning can tell us nothing about whether the outcome of this reasoning is justified. It is not the neuroscience but rather our considered moral judgments that do all the evaluative work in telling us which mental processes we should trust and which we should not.”

“They reject Greene’s inferences about utilitarianism and claim to be restricting themselves to what can be proved scientifically. But in fact all of those I discuss here are making claims about which kinds of moral judgments are good or bad by assessing which are adaptive or maladaptive in relation to a norm of social cooperation.”

“They are thereby relying on an implicit philosophical theory of morality, albeit a much less exacting one than utilitarianism. Rather than adhering to the moral view that we should maximize “utility”—or satisfaction of wants—they are adopting the more minimal, Hobbesian view that our first priority should be to avoid conflict.”

“This minimalist moral worldview is, again, simply presupposed; it is not defended through argument and cannot be substantiated simply by an appeal to scientific facts. And its implications are not altogether appealing.”

“The Harvard psychologist Steven Pinker (who served as a member of the Senior Independent Advisory Panel for the project) there stressed the role of rationality in the form of “nonzero-sum games”—i.e., forms of cooperation in which each party can gain—in fostering cooperative motives, an emphasis that came to play a very significant part in his 2011 book The Better Angels of Our Nature: Why Violence Has Declined.”

“In that extremely influential work Pinker argues that our rational, deliberative modes of evaluation should take precedence over powerful, affective intuitions. But by “rationality” he means specifically “the interchangeability of perspectives and the opportunity the world provides for positive-sum games,” rather than any higher-order philosophical theory. He allows that empathy has played a part in promoting altruism, that “humanitarian reforms are driven in part by an enhanced sensitivity to the experiences of living things and a genuine desire to relieve their suffering.” But nevertheless our “ultimate goal should be policies and norms that become second nature and render empathy unnecessary.””

“Reasoned moral deliberation often does and should override our immediate affective reactions. But Bloom’s view of reasoning, like Haidt’s and Pinker’s, seems oddly restrictive: he equates it with impartiality in the sense of the development of “systems of reward and punishment that apply impartially within the community.” The norm of cooperation is again presupposed as the fundamental means for deciding which of our moral intuitions we should heed.”

“it is a fallacy to suggest that expertise in psychology, a descriptive natural science, can itself qualify someone to determine what is morally right and wrong. The underlying prescriptive moral standards are always presupposed antecedently to any psychological research.”

“In his book Moral Tribes, Joshua Greene warns that even those who seek pragmatic agreement need “an explicit and coherent moral philosophy, a second moral compass that provides direction when gut feelings can’t be trusted.” So in addition to questioning whether psychological research can vindicate moral norms, we also have to ask whether the minimal moral norm of cooperation employed by psychologists is sufficient to provide them with a reliable moral compass.”

“When the Senate Select Committee on Intelligence published its extensive report on official torture in December 2014, Jonathan Haidt tweeted a link to an article by Matt Motyl, his former Ph.D. student, claiming that the report would not change anyone’s views on the morality or effectiveness of torture, owing to the phenomenon of cognitive bias, which distorts people’s assessment of the relevant evidence. Motyl warned that none of us should assume that our beliefs about torture are based on facts. Nevertheless, there are established facts. One of them is that psychologists secured enormous financial gains by collaborating in official torture, while also having clear evidence that it was ineffective.”

“This should be an important lesson concerning our moral frailty, one that should make us wary of conferring moral authority on sources that have no plausible claims to such authority, such as scientists of human behavior. Psychological expertise is a tool that can be used for good or ill. This applies as much to moral psychology as any other field of psychological research. Expertise in teaching people to override their moral intuitions is only a moral good if it serves good ends. Those ends should be determined by rigorous moral deliberation.”

“And it appears that to a certain extent it has. In his 2014 book Head Strong: How Psychology Is Revolutionizing War, Michael Matthews—a professor of engineering psychology at the United States Military Academy and former division head of the APA’s Division 19, the Division for Military Psychology—describes the way in which psychology has come to be seen as a critical tool in the global war on terror. The uses of social psychology and positive psychology, in particular, have come to be priorities for the military.”

“This is in part, Matthews tells us, for the purposes of “winning hearts and minds” both at home and in the field of operations. He also describes one of the most important behavioral goals of the military as the creation of “adaptive killing.” He suggests that

cognitive-based therapy techniques, which focus on eliminating irrational thoughts and beliefs, could be focused on changing a soldier’s belief structure regarding killing. These interventions could be integrated into immersive simulations to promote the conviction that adaptive killing is permissible.”

“A new initiative known as the Comprehensive Soldier Fitness program (CSF) was established in 2009 to explore ways of creating more resilient soldiers by helping them with the necessary psychological adjustments. Seligman devised for the military a metric for assessing “resilience,” the Global Assessment Tool (GAT). Positive Psychology thereby placed itself at the center of the military’s psychological programs.”

“A new initiative known as the Comprehensive Soldier Fitness program (CSF) was established in 2009 to explore ways of creating more resilient soldiers by helping them with the necessary psychological adjustments. Seligman devised for the military a metric for assessing “resilience,” the Global Assessment Tool (GAT). Positive Psychology thereby placed itself at the center of the military’s psychological programs.”

“No psychologist has yet developed a method that can be substituted for moral reflection and reasoning, for employing our own intuitions and principles, weighing them against one another and judging as best we can. This is necessary labor for all of us. We cannot delegate it to higher authorities or replace it with handbooks. Humanly created suffering will continue to demand of us not simply new “technologies of behavior” but genuine moral understanding. We will certainly not find it in the recent books claiming the superior wisdom of psychology.”
